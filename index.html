<!DOCTYPE html>

<head>
    <meta charset="utf-8" />
    <title>Patch-based 3D Natural Scene Generation from a Single Example</title>
    <meta content="Patch-based 3D Natural Scene Generation from a Single Example" name="description" />
    <meta content="summary" name="twitter:card" />
    <meta content="width=device-width, initial-scale=1" name="viewport" />
    <link href="static/css/template.css" rel="stylesheet" type="text/css" />
    <link href="static/css/my_style.css" rel="stylesheet" type="text/css">
    <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css"
        integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous">
    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"
        integrity="sha384-YNHdsYkH6gMx9y3mRkmcJ2mFUjTd0qNQQvY9VYZgQd7DcN7env35GzlmFaZ23JGp"
        crossorigin="anonymous"></script>
    <!-- To automatically render math in text elements, include the auto-render extension: -->
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"
        integrity="sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
    <script type="text/javascript">
        WebFont.load({
            google: {
                families: ["Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic", "Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic", "Ubuntu:300,300italic,400,400italic,500,500italic,700,700italic", "Changa One:400,400italic", "Open Sans:300,300italic,400,400italic,600,600italic,700,700italic,800,800italic", "Varela Round:400", "Bungee Shade:regular", "Roboto:300,regular,500"]
            }
        });
    </script>
    <script type="text/javascript">
        ! function (o, c) {
            var n = c.documentElement,
                t = " w-mod-";
            n.className += t + "js", ("ontouchstart" in o || o.DocumentTouch && c instanceof DocumentTouch) && (n.className += t + "touch")
        }(window, document);
    </script>
    <style>
        .wf-loading * {
            opacity: 0;
        }
    </style>

    <script src="static/js/video_comparison.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
    <style>
        model-viewer {
            cursor: grab;
            display: flex;
            height: 100%;
            width: 100%;
            overflow: hidden;
            position: relative;
            user-select: none;
        }
    </style>

</head>

<body>

    <div class="section hero nerf-_v2">
        <div class="container-2 nerf_header_v2 w-container">
            <h1 class="nerf_title_v2">Patch-based 3D Natural Scene Generation <br> from a Single Example</h1>
            <h1 class="nerf_subheader_v2">Anonymous</h1>
            <div>
                <span class="center"><img src="assets/images/image_teaser.png"></span>
                <p>High-quality artistic imagery created with generated scenes (background sky post-added)</p>
            </div>
        </div>
    </div>


    <div data-anchor="slide1" class="section nerf_section">
        <div class="w-container grey_container">
            <h2 class="grey-heading_nerf">Abstract</h2>
            <p class="paragraph-3 nerf_text nerf_results_text">
                We target a <b>3D generative model</b> for <b>general natural scenes</b> hat are typically unique and intricate.
                Lacking the necessary volumes of training data, along with the difficulties of having ad hoc designs in
                presence of varying scene characteristics, renders existing setups intractable. Inspired by classical
                patch-based image models, we advocate for synthesizing 3D scenes at the patch level, given a single
                example. At the core of this work lies important algorithmic designs w.r.t the scene representation and
                generative patch nearest-neighbor module, that address unique challenges arising from lifting classical
                2D patch-based framework to 3D generation. These design choices, on a collective level, contribute to a
                robust, effective, and efficient model that can generate high-quality general natural scenes with both
                realistic geometric structure and visual appearance, in large quantities and varieties, as demonstrated
                upon a variety of exemplar scenes.
            </p>
        </div>
    </div>


    <div class="white_section_nerf w-container">
        <h2 class="grey-heading_nerf">Random Stynthesis Gallery</h2>

        <div class="white_section_nerf w-container">


            <div class="result_container">
                <div class="h-100 w-25 d-inline-block">
                    <label style="color: rgb(186, 221, 158);"> Exemplar<br></label>
                    <video class="video" id="Cactus_exemplar" loop playsinline autoPlay muted src="assets/videos/Cactus/exemplar.mp4" onplay="resizeAndPlay(this, ['Cactus_s561064', 'Cactus_s910053', 'Cactus_s906756'])"></video>
                    <canvas height=0 class="videoMerge" id="Cactus_exemplar_merge"></canvas>
                </div>
                <div class="h-100 w-25 d-inline-block">
                    <label style="color: rgb(154, 187, 220);"> Generated Scene 1</label>
                    <video class="video" id="Cactus_s561064" loop playsinline autoPlay muted src="assets/videos/Cactus/scene_s561064.mp4"></video>
                    <canvas height=0 class="videoMerge" id="Cactus_s561064_merge"></canvas>
                </div>
                <div class="h-100 w-25 d-inline-block">
                    <label style="color: rgb(154, 187, 220);"> Generated Scene 2</label>
                    <video class="video" id="Cactus_s910053" loop playsinline autoPlay muted src="assets/videos/Cactus/scene_s910053.mp4"></video>
                    <canvas height=0 class="videoMerge" id="Cactus_s910053_merge"></canvas>
                </div>
                <div class="h-100 w-25 d-inline-block">
                    <label style="color: rgb(154, 187, 220);"> Generated Scene 3</label>
                    <video class="video" id="Cactus_s906756" loop playsinline autoPlay muted src="assets/videos/Cactus/scene_s906756.mp4"></video>
                    <canvas height=0 class="videoMerge" id="Cactus_s906756_merge"></canvas>
                </div>
            </div>
    
            <div class="result_container">
                <div class="h-100 w-25 d-inline-block">
                    <video class="video" id="AlphageChurchRuin_exemplar" loop playsinline autoPlay muted
                        src="assets/videos/AlphageChurchRuin/exemplar.mp4"
                        onplay="resizeAndPlay(this, ['AlphageChurchRuin_s401361', 'AlphageChurchRuin_s406232', 'AlphageChurchRuin_s829090'])"></video>
                    <canvas height=0 class="videoMerge" id="AlphageChurchRuin_exemplar_merge"></canvas>
                </div>
                <div class="h-100 w-25 d-inline-block">
                    <video class="video" id="AlphageChurchRuin_s401361" loop playsinline autoPlay muted
                        src="assets/videos/AlphageChurchRuin/scene_s401361.mp4"></video>
                    <canvas height=0 class="videoMerge" id="AlphageChurchRuin_s401361_merge"></canvas>
                </div>
                <div class="h-100 w-25 d-inline-block">
                    <video class="video" id="AlphageChurchRuin_s406232" loop playsinline autoPlay muted
                        src="assets/videos/AlphageChurchRuin/scene_s406232.mp4"></video>
                    <canvas height=0 class="videoMerge" id="AlphageChurchRuin_s406232_merge"></canvas>
                </div>
                <div class="h-100 w-25 d-inline-block">
                    <video class="video" id="AlphageChurchRuin_s829090" loop playsinline autoPlay muted
                        src="assets/videos/AlphageChurchRuin/scene_s829090.mp4"></video>
                    <canvas height=0 class="videoMerge" id="AlphageChurchRuin_s829090_merge"></canvas>
                </div>
            </div>

            <div class="result_container">
                <div class="h-100 w-25 d-inline-block">
                    <video class="video" id="VolcanoIslandLowpoly_new_ocean_exemplar" loop playsinline autoPlay muted src="assets/videos/VolcanoIslandLowpoly_new_ocean/exemplar.mp4" onplay="resizeAndPlay(this, ['VolcanoIslandLowpoly_new_ocean_s415042', 'VolcanoIslandLowpoly_new_ocean_s412378', 'VolcanoIslandLowpoly_new_ocean_s415544'])"></video>
                    <canvas height=0 class="videoMerge" id="VolcanoIslandLowpoly_new_ocean_exemplar_merge"></canvas>
                </div>
                <div class="h-100 w-25 d-inline-block">
                    <video class="video" id="VolcanoIslandLowpoly_new_ocean_s415042" loop playsinline autoPlay muted src="assets/videos/VolcanoIslandLowpoly_new_ocean/scene_s415042.mp4"></video>
                    <canvas height=0 class="videoMerge" id="VolcanoIslandLowpoly_new_ocean_s415042_merge"></canvas>
                </div>
                <div class="h-100 w-25 d-inline-block">
                    <video class="video" id="VolcanoIslandLowpoly_new_ocean_s412378" loop playsinline autoPlay muted src="assets/videos/VolcanoIslandLowpoly_new_ocean/scene_s412378.mp4"></video>
                    <canvas height=0 class="videoMerge" id="VolcanoIslandLowpoly_new_ocean_s412378_merge"></canvas>
                </div>
                <div class="h-100 w-25 d-inline-block">
                    <video class="video" id="VolcanoIslandLowpoly_new_ocean_s415544" loop playsinline autoPlay muted src="assets/videos/VolcanoIslandLowpoly_new_ocean/scene_s415544.mp4"></video>
                    <canvas height=0 class="videoMerge" id="VolcanoIslandLowpoly_new_ocean_s415544_merge"></canvas>
                </div>
            </div>
    
        </div>

        
    </div>


    <div class="white_section_nerf grey_container w-container">
        <h2 class="grey-heading_nerf">Higher-resolution Generation</h2>
        <p class="paragraph-3 nerf_text nerf_results_text">
            A novel ”A Thousand Li of Rivers and Mountains” is rendered from a generated 3D sample.
            The resolution of the scene is 1328 × 512 × 200, and the image resolution is 4096 × 1024.
        </p>
        <div class="csslider infinity" id="slider1">
            <input type="radio" name="slides" checked="checked" id="slides_1" />
            <input type="radio" name="slides" id="slides_2" />
            <input type="radio" name="slides" id="slides_3" />
            <input type="radio" name="slides" id="slides_4" />
            <input type="radio" name="slides" id="slides_5" />
            <ul>
                <li>
                    <img src="assets/images/high_reso/scene_s11340_00010.png">
                </li>
                <li>
                    <img src="assets/images/high_reso/scene_s20450_00010.png">
                </li>
                <li>
                    <img src="assets/images/high_reso/scene_s23490_00010.png">
                </li>
                <li>
                    <img src="assets/images/high_reso/scene_s31887_00010.png">
                </li>
                <li>
                    <img src="assets/images/high_reso/scene_s56223_00010.png">
                </li>
                <li>
                    <img src="assets/images/high_reso/scene_s8304_00010.png">
                </li>
            </ul>
            <!-- <div class="arrows">
                <label for="slides_1"></label>
                <label for="slides_2"></label>
                <label for="slides_3"></label>
                <label for="slides_4"></label>
                <label for="slides_5"></label>
                <label class="goto-first" for="slides_1"></label>
                <label class="goto-last" for="slides_5"></label>
            </div> -->
            <div class="navigation">
                <div>
                    <label for="slides_1"></label>
                    <label for="slides_2"></label>
                    <label for="slides_3"></label>
                    <label for="slides_4"></label>
                    <label for="slides_5"></label>
                </div>
            </div>
        </div>

    </div>

    <div class="white_section_nerf w-container">
        <h2 class="grey-heading_nerf">Eiditing</h2>
        <p class="paragraph-3 nerf_text nerf_results_text">
            Users can manipulate on a 3D
            proxy, which can be the underlining mapping field or mesh,
            for editing scenes, such as removal, duplication, and modification.
        </p>
        <video class="video" id="Eiditing" loop playsinline autoPlay muted
        src="assets/videos/editing.mp4"></video>
    </div>

    <div class="white_section_nerf grey_container w-container">
        <h2 class="grey-heading_nerf">Retargeting</h2>
        <p class="paragraph-3 nerf_text nerf_results_text">
            Our method can resize a 3D scene to a target size while maintaining the
            local patches in the exemplar.
        </p>
        <video class="video" id="Retargeting" loop playsinline autoPlay muted
        src="assets/videos/retargeting.mp4"></video>
    </div>

    <div class="white_section_nerf w-container">
        <h2 class="grey-heading_nerf">Structural Analogies</h2>
        <p class="paragraph-3 nerf_text nerf_results_text">
            Given two scenes A and B, we create a scene with the patch distribution of A, but which is structurally aligned with B.
        </p>
        <video class="video" id="Structural_Analogies" loop playsinline autoPlay muted
        src="assets/videos/structural_analogies.mp4"></video>
    </div>

    <div class="white_section_nerf grey_container w-container">
        <h2 class="grey-heading_nerf" >Re-decoration</h2>
        <p class="paragraph-3 nerf_text nerf_results_text">
            With the coordinate-based representation, we can re-decorate the generated ones with ease, via simply remapping to exemplars of different appearance.
        </p>
        <video class="video" style="margin-top: -20px;" id="Re-decoration" loop playsinline autoPlay muted
        src="assets/videos/re-decoration.mp4"></video>
    </div>
    
    <div class="white_section_nerf w-container">
        <h2 class="grey-heading_nerf">Real-world Results</h2>
        <p class="paragraph-3 nerf_text nerf_results_text">
            Samples generated with images collected from a real-world scenic site – Bryce canyon <a href="https://www.google.com/help/terms_maps/">©2022 Google</a>.
            Notably, we only synthesize the region of interest (i.e., the odd rocks) 
            and the background is disentangled out by modeling with an independent implicit neural network.
        </p>



        <video class="video" id="Real-world" loop playsinline autoPlay muted
        src="assets/videos/real-world.mp4"></video>
    </div>

</body>


</html>